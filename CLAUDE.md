# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## What This Project Is

A Crossplane Configuration (`dot-inference`) that provides a minimal API for deploying LLM inference workloads on Kubernetes using vLLM Production Stack. Users specify `model`, `gpu`, `ingressHost`, and `providerConfigName` — the composition function derives everything else (CPU, memory, tensor parallelism, probes, env vars).

## Environment

We are already in a DevBox Shell when working. Do not prefix commands with `devbox run` or `devbox shell` — just run them directly.

## Commands

Tests output should be redirected to `./tmp/` for review.

```bash
task cluster-create          # KinD + Crossplane + providers + functions + VLLMRuntime CRD
task cluster-destroy         # Tear down KinD cluster
task package-generate        # Embed python/composition.py into package/composition.yaml
task package-apply           # Apply XRD + Composition to cluster
task package-generate-apply  # Both in sequence
task test-e2e                # package-generate-apply + chainsaw test
task test                    # Full cycle: cluster-create → test → cluster-destroy
task package-publish         # Build xpkg + push to Upbound Marketplace (needs UP_TOKEN, UP_ACCOUNT, VERSION)
```

Run tests with output capture: `task test-e2e 2>&1 | tee ./tmp/test-output.txt`

## Architecture

```
LLMInference XR (namespace-scoped, Crossplane v2 — no claims)
    → function-pythonic executes inline python/composition.py
        → generates Object (VLLMRuntime CR) + Object (Ingress)
            → provider-kubernetes applies Objects to target cluster via ProviderConfig
                → vLLM Production Stack operator reconciles VLLMRuntime
```

### Key Directories

- **`package/`** — Crossplane Configuration: `crossplane.yaml` (metadata + deps), `definition.yaml` (XRD), `composition.yaml` (generated, gitignored)
- **`python/`** — Source of truth for composition logic: `composition.py` (function code) + `composition.yaml.tmpl` (Composition template with `__PYTHON_SCRIPT__` placeholder)
- **`providers/`** — Provider/function install manifests for local dev cluster (provider-kubernetes, function-pythonic, incluster ProviderConfig)
- **`tests/`** — Chainsaw e2e tests: `definition/` (XRD schema assert) and `llm-inference/` (XR → Object → VLLMRuntime + Ingress assert)
- **`examples/`** — XR examples (`llm-*.yaml`) and provider config examples

### Generation Flow

`python/composition.py` is the source of truth. Never edit `package/composition.yaml` directly — it's generated by `task package-generate` which embeds the Python code (indented 8 spaces) into `python/composition.yaml.tmpl` at the `__PYTHON_SCRIPT__` marker.

### Composed Resources

The composition function generates `kubernetes.m.crossplane.io/v1alpha1` Object resources (namespace-scoped). Each Object wraps either a `VLLMRuntime` CR or an `Ingress`, with `providerConfigRef` pointing to a `ProviderConfig` (namespace-scoped, created by dot-kubernetes for each target cluster). Manifests inside Objects must include explicit `namespace` (from `targetNamespace` or XR namespace).

## Critical Details

- **Image**: Must use `lmcache/vllm-openai:v0.3.13` — the vLLM Production Stack operator expects `/opt/venv/bin/vllm` entrypoint which only exists in the lmcache fork
- **Service port**: Operator creates service on port 80 (not 8000). Ingress routes to port 80
- **Crossplane v2**: Namespace-scoped XRs directly — no Claims. API version `apiextensions.crossplane.io/v2` for XRD
- **function-pythonic**: Class-based Python engine (`xpkg.upbound.io/crossplane-contrib/function-pythonic`). Python code runs inline via `BaseComposite` class with `compose()` method. Supports `autoReady` for automatic XR readiness propagation
- **GPU heuristics**: 1 GPU → 2 CPU/8Gi, 8 GPU → 16 CPU/64Gi. Tensor parallelism = GPU count when > 1. `VLLM_WORKER_MULTIPROC_METHOD=spawn` for multi-GPU
- **Test cluster**: KinD with VLLMRuntime CRD installed (no operator). Tests verify resource creation, not actual vLLM deployment
- **ProviderConfig**: `ProviderConfig` named `incluster` (InjectedIdentity) at `kubernetes.m.crossplane.io/v1alpha1` for testing. Examples use `inference-small`/`inference-large` for remote GPU clusters (created by dot-kubernetes)
- **targetNamespace**: Optional XRD field. Specifies destination namespace on target cluster. Defaults to XR's `metadata.namespace` if not set
- **config.yaml**: At repo root, version auto-updated by release workflow. `providers/dot-kubernetes.yaml` is the dot-kubernetes Configuration (excluded from cluster-create glob in Taskfile)
